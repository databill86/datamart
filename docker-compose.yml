version: '3.2'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.3.1
    restart: on-failure
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Des.enforce.bootstrap.checks=true
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - ES_HEAP_SIZE=4g
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - 9200:9200
    volumes:
      - ./volumes/elasticsearch:/usr/share/elasticsearch/data
  elasticsearch_exporter:
    image: justwatch/elasticsearch_exporter:1.1.0
    restart: on-failure
    command:
      - '--es.uri=http://elasticsearch:9200'
      - '--es.cluster_settings'
      - '--es.indices'
      - '--es.indices_settings'
    ports:
      - 9114
  rabbitmq:
    image: remram/rabbitmq:3.7.8
    build:
      context: ./docker
      dockerfile: rabbitmq.dockerfile
    environment:
      - RABBITMQ_DEFAULT_USER=${AMQP_USER}
      - RABBITMQ_DEFAULT_PASS=${AMQP_PASSWORD}
    ports:
      - 8080:15672
      - 5672:5672
  lazo:
    image: registry.gitlab.com/vida-nyu/datamart/lazo-index-service:0.1.0
    environment:
      - DATABASE=elasticsearch
      - PORT=50051
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - S3_KEY=${S3_KEY}
      - S3_SECRET=${S3_SECRET}
      - S3_URL=${S3_URL}
      - S3_CLIENT_URL=${S3_CLIENT_URL}
      - S3_BUCKET_PREFIX=${S3_BUCKET_PREFIX}
    ports:
      - 50051:50051
  minio:
    image: minio/minio:RELEASE.2019-08-29T00-25-01Z
    command: ["server", "/export"]
    environment:
      - MINIO_ACCESS_KEY=${S3_KEY}
      - MINIO_SECRET_KEY=${S3_SECRET}
    healthcheck:
      disable: true
    ports:
      - 9000:9000
  coordinator:
    build:
      context: .
      dockerfile: coordinator/Dockerfile
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - S3_KEY=${S3_KEY}
      - S3_SECRET=${S3_SECRET}
      - S3_URL=${S3_URL}
      - S3_CLIENT_URL=${S3_CLIENT_URL}
      - S3_BUCKET_PREFIX=${S3_BUCKET_PREFIX}
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - QUERY_HOST=${QUERY_HOST}
      - MAX_CACHE_BYTES=100000000000  # 100 GB
    # CI: command: ["bash", "-c", "set -m; python -Wd -m coverage run --branch -p -m coordinator & PROCESS=$$!; trap \"kill -INT $$PROCESS\" INT TERM; wait $$PROCESS; wait $$PROCESS; cp .coverage* /cov/"]
    ports:
      - 8001:8001
    # CI: volumes:
    # CI:   - ./cov:/cov
  query:
    build:
      context: .
      dockerfile: query/Dockerfile
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - S3_KEY=${S3_KEY}
      - S3_SECRET=${S3_SECRET}
      - S3_URL=${S3_URL}
      - S3_CLIENT_URL=${S3_CLIENT_URL}
      - S3_BUCKET_PREFIX=${S3_BUCKET_PREFIX}
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
    ports:
      - 8002
    # CI: command: ["bash", "-c", "set -m; python -Wd -m coverage run --branch -p -m query & PROCESS=$$!; trap \"kill -INT $$PROCESS\" INT TERM; wait $$PROCESS; wait $$PROCESS; cp .coverage* /cov/"]
    # CI: volumes:
    # CI:   - ./cov:/cov
  querylb:
    build:
      context: ./docker
      dockerfile: haproxy.dockerfile
    restart: on-failure
    ports:
      - 8002:80
      - 8081:8000
    volumes:
      - ./docker/haproxy.conf:/usr/local/etc/haproxy/haproxy.cfg:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 10s
      retries: 2
  profiler:
    build:
      context: .
      dockerfile: profiler/Dockerfile
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - S3_KEY=${S3_KEY}
      - S3_SECRET=${S3_SECRET}
      - S3_URL=${S3_URL}
      - S3_CLIENT_URL=${S3_CLIENT_URL}
      - S3_BUCKET_PREFIX=${S3_BUCKET_PREFIX}
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
    # CI: command: ["bash", "-c", "set -m; python -Wd -m coverage run --branch -p -m profiler & PROCESS=$$!; trap \"kill -INT $$PROCESS\" INT TERM; wait $$PROCESS; wait $$PROCESS; cp .coverage* /cov/"]
    # CI: volumes:
    # CI:   - ./cov:/cov
  prometheus:
    image: prom/prometheus
    ports:
      - 9090:9090
    volumes:
      - ./volumes/prometheus:/prometheus
      - ./docker/prometheus.yml:/etc/prometheus/prometheus.yml
  grafana:
    image: grafana/grafana
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      #- GF_SMTP_ENABLED=true
      #- GF_SMTP_HOST=ip-of-the-host:25
      #- GF_SMTP_FROM_NAME=Datamart Development
      #- GF_SERVER_ROOT_URL=https://grafana.example.org/
    ports:
      - 3000:3000
    volumes:
      - ./volumes/grafana:/var/lib/grafana
  example_discoverer:
    build:
      context: .
      dockerfile: discovery/Dockerfile
    command: example
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
  test_discoverer:
    build:
      context: .
      dockerfile: discovery/Dockerfile
    command: testsuite  # NOTCI
    # CI: command: ["bash", "-c", "set -m; python -Wd -m coverage run --branch -p discovery/test_discovery.py & PROCESS=$$!; trap \"kill -INT $$PROCESS\" INT TERM; wait $$PROCESS; wait $$PROCESS; cp .coverage* /cov/"]
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - S3_KEY=${S3_KEY}
      - S3_SECRET=${S3_SECRET}
      - S3_URL=${S3_URL}
      - S3_CLIENT_URL=${S3_CLIENT_URL}
      - S3_BUCKET_PREFIX=${S3_BUCKET_PREFIX}
      - GCS_PROJECT=${GCS_PROJECT}
      - GCS_CREDS=${GCS_CREDS}
      - GCS_BUCKET_PREFIX=${GCS_BUCKET_PREFIX}
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
    # CI: volumes:
    # CI:   - ./cov:/cov
  socrata:
    build:
      context: .
      dockerfile: discovery/socrata/Dockerfile
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - S3_KEY=${S3_KEY}
      - S3_SECRET=${S3_SECRET}
      - S3_URL=${S3_URL}
      - S3_CLIENT_URL=${S3_CLIENT_URL}
      - S3_BUCKET_PREFIX=${S3_BUCKET_PREFIX}
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
  noaa:
    build:
      context: .
      dockerfile: discovery/noaa/Dockerfile
    environment:
      - ELASTICSEARCH_HOSTS=elasticsearch:9200
      - AMQP_HOST=rabbitmq
      - AMQP_USER=${AMQP_USER}
      - AMQP_PASSWORD=${AMQP_PASSWORD}
      - NOAA_TOKEN=${NOAA_TOKEN}
      - LAZO_SERVER_HOST=lazo
      - LAZO_SERVER_PORT=50051
